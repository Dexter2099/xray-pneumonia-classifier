{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pneumonia Classifier Demonstration\n",
    "\n",
    "This notebook demonstrates how to load the pretrained pneumonia classifier, perform inference on a chest X-ray image and visualize the important regions using Grad-CAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from src.model import SimpleCNN\n",
    "from src.gradcam import GradCAM\n",
    "\n",
    "# load config\n",
    "with open('src/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN().to(device)\n",
    "model.load_state_dict(torch.load('outputs/checkpoints/best_model.pth', map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a sample X-ray image\n",
    "img_path = 'data/raw/chest_xray/test/NORMAL/IM-0001-0001.jpeg'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "image = Image.open(img_path).convert('L')\n",
    "input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "    probs = torch.softmax(output, dim=1)\n",
    "    pred = probs.argmax(dim=1).item()\n",
    "\n",
    "classes = ['NORMAL', 'PNEUMONIA']\n",
    "print('Predicted class:', classes[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradcam = GradCAM(model, model.conv3)\n",
    "cam = gradcam.generate(input_tensor)\n",
    "\n",
    "img = np.array(image.resize((224, 224)))\n",
    "heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "overlay = cv2.addWeighted(cv2.cvtColor(img, cv2.COLOR_GRAY2BGR), 0.6, heatmap, 0.4, 0)\n",
    "\n",
    "plt.imshow(overlay)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
